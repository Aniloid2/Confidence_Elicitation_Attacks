high_level_folder: texthoaxer_test2
test_folder: texthoaxer_test2/llama3_sst2_log_folder
args Namespace(api_key='', cache_dir='/home/brian/.cache/CEAttacks', cache_transformers='/mnt/hdd/brian/', confidence_type='weighted_confidence', experiment_name_folder='texthoaxer_test2', high_level_folder='texthoaxer_test2', index_order_technique='random', k_pred=20, max_iter_i=5, model_precision='float32', model_type='llama3', n_embeddings=10, name_of_test='EN500_MTllama3_TAsst2_PTstep2_k_pred_avg_PSTzs_STUSE_NT2', num_examples=500, num_transformations=2, prompt_shot_type='zs', prompting_type='step2_k_pred_avg', query_budget=500, search_method='texthoaxer_search', seed=42, similarity_technique='USE', similarity_threshold=0.5, task='sst2', task_structure='classification', temperature=0.001, ternary_plot=False, test_folder='texthoaxer_test2/llama3_sst2_log_folder', transformation_method='texthoaxer')
Selected transformation method 'texthoaxer' is of type 'word_level'.
Selected transformation method 'sst2' is of type 'classification'.
Arguments Namespace args:
  - Model type: llama3
  - Model precision: float32
  - Task: sst2
  - Task structure: classification
  - Confidence type: weighted_confidence
  - Prompting type: step2_k_pred_avg
  - Search method: texthoaxer_search
  - Transformation method: texthoaxer
  - N embeddings: 10
  - Prompt shot type: zs
  - K pred: 20
  - Max iter i: 5
  - Query budget: 500
  - Num examples: 500
  - Similarity technique: USE
  - Similarity threshold: 0.5
  - Num transformations: 2
  - Index order technique: random
  - Cache transformers: /mnt/hdd/brian/
  - Cache dir: /home/brian/.cache/CEAttacks
  - Experiment name folder: texthoaxer_test2
  - Temperature: 0.001
  - Ternary plot: False
  - Seed: 42
  - Api key: 
  - Test folder: texthoaxer_test2/llama3_sst2_log_folder
  - High level folder: texthoaxer_test2
  - Name of test: EN500_MTllama3_TAsst2_PTstep2_k_pred_avg_PSTzs_STUSE_NT2
  - Ceattack logger: <Logger Calibra (DEBUG)>
  - Transformation type: word_level
  - Task type: classification
Loading sst2 dataset from stanfordnlp/sst2...
sst2 dataset loaded successfully <class 'datasets.arrow_dataset.Dataset'> column names ['idx', 'sentence', 'label']
types <class 'datasets.arrow_dataset.Dataset'> True
Total filtered dataset size: 500
File already exists at: /home/brian/.cache/CEAttacks/texthoaxer/mat.txt
Saving to: texthoaxer_test2/llama3_sst2_log_folder EN500_MTllama3_TAsst2_PTstep2_k_pred_avg_PSTzs_STUSE_NT2
Attack(
  (search_method): TextHoaxerSearch
  (goal_function):  Prediction_And_Confidence_GoalFunction
  (transformation):  HigherWordSwapEmbedding(
    (max_candidates):  10
    (embedding):  WordEmbedding
  )
  (constraints): 
    (0): WordEmbeddingDistance(
        (embedding):  WordEmbedding
        (min_cos_sim):  0.5
        (cased):  False
        (include_unknown_words):  True
        (compare_against_original):  True
      )
    (1): PartOfSpeech(
        (tagger_type):  nltk
        (tagset):  universal
        (allow_verb_noun_swap):  True
        (compare_against_original):  True
      )
    (2): RepeatModification
    (3): StopwordModification
    (4): InputColumnModification(
        (matching_column_labels):  ['premise', 'hypothesis']
        (columns_to_ignore):  {'premise'}
      )
  (is_black_box):  True
) 

initializing a new example
List of samples to attack: [<AttackedText "it 's a charming and often affecting journey . ">]
Final number of queries: 1
Datapoint: it 's a charming and often affecting journey . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$it 's a charming and often affecting journey .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive']
Counter: {'sst2': {'negative': 0, 'positive': 20, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$it 's a charming and often affecting journey . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

The text is: it's a charming and often affecting journey.

The guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']

Confidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high
Raw output: {'raw_responses': "\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nThe text is: it's a charming and often affecting journey.\n\nThe guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high", 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive', 'confidences': "\n\nThe text is: it's a charming and often affecting journey.\n\nThe guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high"}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']
Standarized numerical confidence result: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': "\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nThe text is: it's a charming and often affecting journey.\n\nThe guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high", 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]}
Output that needs aggregation: {'raw_responses': "\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nThe text is: it's a charming and often affecting journey.\n\nThe guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high", 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], 'inference_step': 0, 'current_sample_id': 1}
Weighted count of prediction weight plus confidence weight: {'negative': 0.0, 'positive': 80.0, 'null': 0.0}
Sample ID: 1 and Inference step 0
Counts: {'sst2': {'negative': 0, 'positive': 40, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
Weighted Counts: {'negative': 0.0, 'positive': 80.0, 'null': 0.0}
Alpha Vector: [1.0, 81.0, 1.0]
Empirical Mean [0.01279359 0.97486934 0.01233707]
Probabilities: [0.00975015 0.9858009  0.00444895]
Second Order Uncertainty: [0.0001417027835956563, 0.00027994940173776, 0.0001417027835956563]
words_perturb [6, 7, 5, 3]
start_i 3
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('charming', 'NN'), ('and', 'CC'), ('often', 'RB'), ('affecting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a charmer and often affecting journey . ">, <AttackedText "it 's a charms and often affecting journey . ">, <AttackedText "it 's a cute and often affecting journey . ">, <AttackedText "it 's a enchanting and often affecting journey . ">, <AttackedText "it 's a ravishing and often affecting journey . ">] 5
words_perturb [6, 7, 5, 3]
start_i 5
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('enchanting', 'NN'), ('and', 'CC'), ('often', 'RB'), ('affecting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a enchanting and commonly affecting journey . ">, <AttackedText "it 's a enchanting and frequently affecting journey . ">, <AttackedText "it 's a enchanting and habitually affecting journey . ">, <AttackedText "it 's a enchanting and normally affecting journey . ">, <AttackedText "it 's a enchanting and ordinarily affecting journey . ">, <AttackedText "it 's a enchanting and routinely affecting journey . ">, <AttackedText "it 's a enchanting and traditionally affecting journey . ">, <AttackedText "it 's a enchanting and typically affecting journey . ">, <AttackedText "it 's a enchanting and usually affecting journey . ">] 9
words_perturb [6, 7, 5, 3]
start_i 6
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('enchanting', 'NN'), ('and', 'CC'), ('ordinarily', 'RB'), ('affecting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a enchanting and ordinarily affect journey . ">, <AttackedText "it 's a enchanting and ordinarily affects journey . ">, <AttackedText "it 's a enchanting and ordinarily afflicting journey . ">, <AttackedText "it 's a enchanting and ordinarily impact journey . ">, <AttackedText "it 's a enchanting and ordinarily impacting journey . ">, <AttackedText "it 's a enchanting and ordinarily impacts journey . ">, <AttackedText "it 's a enchanting and ordinarily influence journey . ">, <AttackedText "it 's a enchanting and ordinarily influenced journey . ">, <AttackedText "it 's a enchanting and ordinarily influences journey . ">, <AttackedText "it 's a enchanting and ordinarily influencing journey . ">] 10
words_perturb [6, 7, 5, 3]
start_i 7
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('enchanting', 'NN'), ('and', 'CC'), ('ordinarily', 'RB'), ('afflicting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a enchanting and ordinarily afflicting journeys . ">, <AttackedText "it 's a enchanting and ordinarily afflicting travel . ">, <AttackedText "it 's a enchanting and ordinarily afflicting traveling . ">, <AttackedText "it 's a enchanting and ordinarily afflicting travelling . ">, <AttackedText "it 's a enchanting and ordinarily afflicting travels . ">, <AttackedText "it 's a enchanting and ordinarily afflicting trip . ">, <AttackedText "it 's a enchanting and ordinarily afflicting trips . ">, <AttackedText "it 's a enchanting and ordinarily afflicting voyage . ">, <AttackedText "it 's a enchanting and ordinarily afflicting voyages . ">] 9
words_perturb [6, 7, 5, 3]
start_i 3
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('charming', 'NN'), ('and', 'CC'), ('often', 'RB'), ('affecting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a charmer and often affecting journey . ">, <AttackedText "it 's a charms and often affecting journey . ">, <AttackedText "it 's a cute and often affecting journey . ">, <AttackedText "it 's a enchanting and often affecting journey . ">, <AttackedText "it 's a ravishing and often affecting journey . ">] 5
words_perturb [6, 7, 5, 3]
start_i 5
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('charmer', 'NN'), ('and', 'CC'), ('often', 'RB'), ('affecting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a charmer and commonly affecting journey . ">, <AttackedText "it 's a charmer and frequently affecting journey . ">, <AttackedText "it 's a charmer and habitually affecting journey . ">, <AttackedText "it 's a charmer and normally affecting journey . ">, <AttackedText "it 's a charmer and ordinarily affecting journey . ">, <AttackedText "it 's a charmer and routinely affecting journey . ">, <AttackedText "it 's a charmer and traditionally affecting journey . ">, <AttackedText "it 's a charmer and typically affecting journey . ">, <AttackedText "it 's a charmer and usually affecting journey . ">] 9
words_perturb [6, 7, 5, 3]
start_i 6
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('charmer', 'NN'), ('and', 'CC'), ('usually', 'RB'), ('affecting', 'VBG'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a charmer and usually affect journey . ">, <AttackedText "it 's a charmer and usually affects journey . ">, <AttackedText "it 's a charmer and usually afflicting journey . ">, <AttackedText "it 's a charmer and usually impacting journey . ">, <AttackedText "it 's a charmer and usually impacts journey . ">, <AttackedText "it 's a charmer and usually influence journey . ">, <AttackedText "it 's a charmer and usually influenced journey . ">, <AttackedText "it 's a charmer and usually influences journey . ">, <AttackedText "it 's a charmer and usually influencing journey . ">] 9
words_perturb [6, 7, 5, 3]
start_i 7
pos_tags nltk [('it', 'PRP'), ('s', 'VBZ'), ('a', 'DT'), ('charmer', 'NN'), ('and', 'CC'), ('usually', 'RB'), ('affect', 'VBP'), ('journey', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "it 's a charmer and usually affect journeys . ">, <AttackedText "it 's a charmer and usually affect travel . ">, <AttackedText "it 's a charmer and usually affect traveling . ">, <AttackedText "it 's a charmer and usually affect travelling . ">, <AttackedText "it 's a charmer and usually affect travels . ">, <AttackedText "it 's a charmer and usually affect trip . ">, <AttackedText "it 's a charmer and usually affect trips . ">, <AttackedText "it 's a charmer and usually affect voyage . ">, <AttackedText "it 's a charmer and usually affect voyages . ">] 9
List of samples to attack: [<AttackedText "it 's a enchanting and ordinarily afflicting traveling . ">, <AttackedText "it 's a charmer and usually affect trips . ">]
Final number of queries: 5
Datapoint: it 's a enchanting and ordinarily afflicting traveling . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$it 's a enchanting and ordinarily afflicting traveling .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 10, 'positive': 10, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$it 's a enchanting and ordinarily afflicting traveling . $ the guesses were: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

The text is: it's a enchanting and ordinarily afflicting traveling.

Guesses: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']

Confidences: [low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, high, high]
Raw output: {'raw_responses': "\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nThe text is: it's a enchanting and ordinarily afflicting traveling.\n\nGuesses: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']\n\nConfidences: [low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, high, high]", 'predictions': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive', 'confidences': "\n\nThe text is: it's a enchanting and ordinarily afflicting traveling.\n\nGuesses: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']\n\nConfidences: [low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, high, high]"}
Standarized predictions result: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 4, 4]
Guessed output and label list: Guess: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': "\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nThe text is: it's a enchanting and ordinarily afflicting traveling.\n\nGuesses: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']\n\nConfidences: [low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, high, high]", 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 4, 4]}
Output that needs aggregation: {'raw_responses': "\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nThe text is: it's a enchanting and ordinarily afflicting traveling.\n\nGuesses: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']\n\nConfidences: [low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, low, high, low, medium, high, high]", 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 4, 4], 'inference_step': 0, 'current_sample_id': 1}
Weighted count of prediction weight plus confidence weight: {'negative': 22.0, 'positive': 35.0, 'null': 0.0}
Sample ID: 1 and Inference step 0
Counts: {'sst2': {'negative': 20, 'positive': 20, 'null': 0}}
Numerical Confidences: [2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 2, 4, 2, 3, 4, 4]
Weighted Counts: {'negative': 22.0, 'positive': 35.0, 'null': 0.0}
Alpha Vector: [23.0, 36.0, 1.0]
Empirical Mean [0.3794552  0.60463375 0.01591105]
Probabilities: [0.42431233 0.56105358 0.0146341 ]
Second Order Uncertainty: [0.0038752276867030965, 0.003934426229508197, 0.0002686703096539162]
Datapoint: it 's a charmer and usually affect trips . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$it 's a charmer and usually affect trips .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 8, 'positive': 12, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$it 's a charmer and usually affect trips . $ the guesses were: ['positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, low, high, high, low, high, low, high, high, low, high, low, high, low, high, high, low, high
Raw output: {'raw_responses': '\n\nPositive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive \n\nConfidences: high, high, medium, low, high, high, low, high, low, high, high, low, high, low, high, low, high, high, low, high', 'predictions': '\n\nPositive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive', 'confidences': '\n\nConfidences: high, high, medium, low, high, high, low, high, low, high, high, low, high, low, high, low, high, high, low, high'}
Standarized predictions result: ['positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 3, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4]
Guessed output and label list: Guess: ['positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive \n\nConfidences: high, high, medium, low, high, high, low, high, low, high, high, low, high, low, high, low, high, high, low, high', 'predictions': ['positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 3, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive \n\nConfidences: high, high, medium, low, high, high, low, high, low, high, high, low, high, low, high, low, high, high, low, high', 'predictions': ['positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 3, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4], 'inference_step': 1, 'current_sample_id': 1}
Weighted count of prediction weight plus confidence weight: {'negative': 18.0, 'positive': 47.0, 'null': 0.0}
Sample ID: 1 and Inference step 1
Counts: {'sst2': {'negative': 16, 'positive': 24, 'null': 0}}
Numerical Confidences: [4, 4, 3, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4]
Weighted Counts: {'negative': 18.0, 'positive': 47.0, 'null': 0.0}
Alpha Vector: [19.0, 48.0, 1.0]
Empirical Mean [0.28174398 0.70388918 0.01436684]
Probabilities: [0.22591547 0.77223045 0.00185407]
Second Order Uncertainty: [0.0029179830499974926, 0.0030088761847449977, 0.00020999448372699463]
returning failed result because flag==0
color_method None
initializing a new example
List of samples to attack: [<AttackedText "allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . ">]
Final number of queries: 1
Datapoint: allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 1, 'positive': 19, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], 'inference_step': 0, 'current_sample_id': 2}
Weighted count of prediction weight plus confidence weight: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Sample ID: 2 and Inference step 0
Counts: {'sst2': {'negative': 2, 'positive': 38, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Weighted Counts: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Alpha Vector: [6.0, 77.0, 1.0]
Empirical Mean [0.07085339 0.91688528 0.01226133]
Probabilities: [0.05368131 0.94477636 0.00154233]
Second Order Uncertainty: [0.00078031212484994, 0.0008986928104575163, 0.00013838868880885688]
words_perturb [18, 12, 16, 15, 7]
start_i 7
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('poised', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('career', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "allows us to hope that nolan is authored to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is lending to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is prepared to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is prepped to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is readies to embark a major career as a commercial yet inventive filmmaker . ">] 7
words_perturb [18, 12, 16, 15, 7]
start_i 12
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('braced', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('career', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "allows us to hope that nolan is braced to embark a major careers as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major carrera as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major occupational as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major occupations as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major profession as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major professions as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarries as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major racing as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major vocational as a commercial yet inventive filmmaker . ">] 10
words_perturb [18, 12, 16, 15, 7]
start_i 15
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('braced', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('quarry', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [18, 12, 16, 15, 7]
start_i 16
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('braced', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('quarry', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [18, 12, 16, 15, 7]
start_i 18
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('braced', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('quarry', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive auteur . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive cinematographer . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive cinematographers . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive director . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive directors . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive filmmakers . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive headmaster . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive headmistress . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive screenwriter . ">, <AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive scriptwriter . ">] 10
words_perturb [18, 12, 16, 15, 7]
start_i 7
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('poised', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('career', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "allows us to hope that nolan is authored to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is braced to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is lending to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is prepared to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is prepped to embark a major career as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is readies to embark a major career as a commercial yet inventive filmmaker . ">] 7
words_perturb [18, 12, 16, 15, 7]
start_i 12
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('devised', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('career', 'NN'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major carrera as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major occupational as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major occupations as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major profession as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major professions as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major quarries as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major quarry as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major racing as a commercial yet inventive filmmaker . ">, <AttackedText "allows us to hope that nolan is devised to embark a major vocational as a commercial yet inventive filmmaker . ">] 10
words_perturb [18, 12, 16, 15, 7]
start_i 15
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('devised', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('careers', 'NNS'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [18, 12, 16, 15, 7]
start_i 16
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('devised', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('careers', 'NNS'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [18, 12, 16, 15, 7]
start_i 18
pos_tags nltk [('allows', 'NNS'), ('us', 'PRP'), ('to', 'TO'), ('hope', 'VB'), ('that', 'DT'), ('nolan', 'NN'), ('is', 'VBZ'), ('devised', 'VBN'), ('to', 'TO'), ('embark', 'VB'), ('a', 'DT'), ('major', 'JJ'), ('careers', 'NNS'), ('as', 'IN'), ('a', 'DT'), ('commercial', 'JJ'), ('yet', 'RB'), ('inventive', 'JJ'), ('filmmaker', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive auteur . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive cinematographer . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive cinematographers . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive director . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive directors . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive filmmakers . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive headmaster . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive headmistress . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive screenwriter . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive scriptwriter . ">] 10
List of samples to attack: [<AttackedText "allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive headmistress . ">, <AttackedText "allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive filmmakers . ">]
Final number of queries: 5
Datapoint: allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive headmistress . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive headmistress .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative']
Counter: {'sst2': {'negative': 9, 'positive': 11, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$allows us to hope that nolan is braced to embark a major quarry as a commercial yet inventive headmistress . $ the guesses were: ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, low, high, low, high, high, low, high, low, high, low, high, high, low, high, low, high, low
Raw output: {'raw_responses': '\n\nPositive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative \n\nConfidences: high, high, medium, low, high, low, high, high, low, high, low, high, low, high, high, low, high, low, high, low', 'predictions': '\n\nPositive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative', 'confidences': '\n\nConfidences: high, high, medium, low, high, low, high, high, low, high, low, high, low, high, high, low, high, low, high, low'}
Standarized predictions result: ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 3, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2]
Guessed output and label list: Guess: ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative \n\nConfidences: high, high, medium, low, high, low, high, high, low, high, low, high, low, high, high, low, high, low, high, low', 'predictions': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative'], 'confidences': [4, 4, 3, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Positive, Negative, Positive, Negative, Positive, Negative \n\nConfidences: high, high, medium, low, high, low, high, high, low, high, low, high, low, high, high, low, high, low, high, low', 'predictions': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative'], 'confidences': [4, 4, 3, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2], 'inference_step': 0, 'current_sample_id': 2}
Weighted count of prediction weight plus confidence weight: {'negative': 20.0, 'positive': 43.0, 'null': 0.0}
Sample ID: 2 and Inference step 0
Counts: {'sst2': {'negative': 18, 'positive': 22, 'null': 0}}
Numerical Confidences: [4, 4, 3, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2]
Weighted Counts: {'negative': 20.0, 'positive': 43.0, 'null': 0.0}
Alpha Vector: [21.0, 44.0, 1.0]
Empirical Mean [0.31616992 0.66867263 0.01515745]
Probabilities: [0.24011626 0.75147798 0.00840577]
Second Order Uncertainty: [0.003237942518810904, 0.003316749585406302, 0.0002227156229869934]
Datapoint: allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive filmmakers . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive filmmakers .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 5, 'positive': 15, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$allows us to hope that nolan is devised to embark a major careers as a commercial yet inventive filmmakers . $ the guesses were: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low', 'predictions': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low'}
Standarized predictions result: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low', 'predictions': ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low', 'predictions': ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2], 'inference_step': 1, 'current_sample_id': 2}
Weighted count of prediction weight plus confidence weight: {'negative': 10.0, 'positive': 60.0, 'null': 0.0}
Sample ID: 2 and Inference step 1
Counts: {'sst2': {'negative': 10, 'positive': 30, 'null': 0}}
Numerical Confidences: [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2]
Weighted Counts: {'negative': 10.0, 'positive': 60.0, 'null': 0.0}
Alpha Vector: [11.0, 61.0, 1.0]
Empirical Mean [0.15083085 0.83586782 0.01330133]
Probabilities: [0.25704717 0.73331675 0.00963608]
Second Order Uncertainty: [0.0017294457151841277, 0.0018562379230422014, 0.00018258077931562638]
returning failed result because flag==0
color_method None
initializing a new example
List of samples to attack: [<AttackedText "the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">]
Final number of queries: 1
Datapoint: the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive']
Counter: {'sst2': {'negative': 0, 'positive': 20, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

The text is: the film's narrative is somewhat predictable and relies heavily on familiar tropes.

Confidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest
Raw output: {'raw_responses': "\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nThe text is: the film's narrative is somewhat predictable and relies heavily on familiar tropes.\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest", 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive', 'confidences': "\n\nThe text is: the film's narrative is somewhat predictable and relies heavily on familiar tropes.\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest"}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']
Standarized numerical confidence result: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': "\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nThe text is: the film's narrative is somewhat predictable and relies heavily on familiar tropes.\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest", 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]}
Output that needs aggregation: {'raw_responses': "\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nThe text is: the film's narrative is somewhat predictable and relies heavily on familiar tropes.\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest", 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], 'inference_step': 0, 'current_sample_id': 3}
Weighted count of prediction weight plus confidence weight: {'negative': 0.0, 'positive': 81.0, 'null': 0.0}
Sample ID: 3 and Inference step 0
Counts: {'sst2': {'negative': 0, 'positive': 40, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Weighted Counts: {'negative': 0.0, 'positive': 81.0, 'null': 0.0}
Alpha Vector: [1.0, 82.0, 1.0]
Empirical Mean [0.01178744 0.9759418  0.01227076]
Probabilities: [0.01718933 0.95809201 0.02471866]
Second Order Uncertainty: [0.00013838868880885688, 0.0002734427104175003, 0.00013838868880885688]
words_perturb [7, 1, 12, 10, 9]
start_i 1
pos_tags nltk [('the', 'DT'), ('acting', 'VBG'), ('costumes', 'NNS'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('astounding', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the behaved , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">] 3
words_perturb [7, 1, 12, 10, 9]
start_i 7
pos_tags nltk [('the', 'DT'), ('behaving', 'NN'), ('costumes', 'NNS'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('astounding', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [] 0
words_perturb [7, 1, 12, 10, 9]
start_i 9
pos_tags nltk [('the', 'DT'), ('behaving', 'NN'), ('costumes', 'NNS'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('astounding', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the behaving , costumes , music , cinematography and sound are all astonishing given the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking given the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all staggering given the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all startling given the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all stunning given the production 's austere locales . ">] 5
words_perturb [7, 1, 12, 10, 9]
start_i 10
pos_tags nltk [('the', 'DT'), ('behaving', 'NN'), ('costumes', 'NNS'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('breathtaking', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking accorded the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking afforded the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking awarded the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking bestowed the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking conferred the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking gave the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking granted the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking provided the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking yielded the production 's austere locales . ">] 10
words_perturb [7, 1, 12, 10, 9]
start_i 12
pos_tags nltk [('the', 'DT'), ('behaving', 'NN'), ('costumes', 'NNS'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('breathtaking', 'VBG'), ('supplied', 'VBD'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the fabrication 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the generating 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufacture 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufactures 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufacturing 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the produce 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the producer 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the producing 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the productivity 's austere locales . ">] 9
words_perturb [7, 1, 12, 10, 9]
start_i 1
pos_tags nltk [('the', 'DT'), ('acting', 'VBG'), ('costumes', 'NNS'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('astounding', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the behaved , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">, <AttackedText "the behaving , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all astounding given the production 's austere locales . ">] 3
words_perturb [7, 1, 12, 10, 9]
start_i 7
pos_tags nltk [('the', 'DT'), ('caretaker', 'NN'), ('costumes', 'VBZ'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('astounding', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [] 0
words_perturb [7, 1, 12, 10, 9]
start_i 9
pos_tags nltk [('the', 'DT'), ('caretaker', 'NN'), ('costumes', 'VBZ'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('astounding', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the caretaker , costumes , music , cinematography and sound are all astonishing given the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all breathtaking given the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all staggering given the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling given the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all stunning given the production 's austere locales . ">] 5
words_perturb [7, 1, 12, 10, 9]
start_i 10
pos_tags nltk [('the', 'DT'), ('caretaker', 'NN'), ('costumes', 'VBZ'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('startling', 'VBG'), ('given', 'VBN'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the caretaker , costumes , music , cinematography and sound are all startling accorded the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling afforded the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling awarded the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling bestowed the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling gave the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling granted the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling provided the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling supplied the production 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling yielded the production 's austere locales . ">] 10
words_perturb [7, 1, 12, 10, 9]
start_i 12
pos_tags nltk [('the', 'DT'), ('caretaker', 'NN'), ('costumes', 'VBZ'), ('music', 'NN'), ('cinematography', 'NN'), ('and', 'CC'), ('sound', 'NN'), ('are', 'VBP'), ('all', 'DT'), ('startling', 'JJ'), ('conferred', 'VBD'), ('the', 'DT'), ('production', 'NN'), ('s', 'NN'), ('austere', 'JJ'), ('locales', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the fabrication 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the generating 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the manufacture 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the manufactures 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the manufacturing 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the produce 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the producer 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the producing 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the productivity 's austere locales . ">] 9
List of samples to attack: [<AttackedText "the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufacturing 's austere locales . ">, <AttackedText "the caretaker , costumes , music , cinematography and sound are all startling conferred the manufactures 's austere locales . ">]
Final number of queries: 5
Datapoint: the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufacturing 's austere locales . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufacturing 's austere locales .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 1, 'positive': 19, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$the behaving , costumes , music , cinematography and sound are all breathtaking supplied the manufacturing 's austere locales . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], 'inference_step': 0, 'current_sample_id': 3}
Weighted count of prediction weight plus confidence weight: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Sample ID: 3 and Inference step 0
Counts: {'sst2': {'negative': 2, 'positive': 38, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Weighted Counts: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Alpha Vector: [6.0, 77.0, 1.0]
Empirical Mean [0.06998258 0.9182868  0.01173061]
Probabilities: [0.11191916 0.85482339 0.03325745]
Second Order Uncertainty: [0.00078031212484994, 0.0008986928104575163, 0.00013838868880885688]
Datapoint: the caretaker , costumes , music , cinematography and sound are all startling conferred the manufactures 's austere locales . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$the caretaker , costumes , music , cinematography and sound are all startling conferred the manufactures 's austere locales .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 6, 'positive': 14, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$the caretaker , costumes , music , cinematography and sound are all startling conferred the manufactures 's austere locales . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative \n\nConfidences: high, high, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low', 'predictions': '\n\nPositive, Positive, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative \n\nConfidences: high, high, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low', 'predictions': ['positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative \n\nConfidences: high, high, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low, high, high, low', 'predictions': ['positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2], 'inference_step': 1, 'current_sample_id': 3}
Weighted count of prediction weight plus confidence weight: {'negative': 12.0, 'positive': 56.0, 'null': 0.0}
Sample ID: 3 and Inference step 1
Counts: {'sst2': {'negative': 12, 'positive': 28, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2]
Weighted Counts: {'negative': 12.0, 'positive': 56.0, 'null': 0.0}
Alpha Vector: [13.0, 57.0, 1.0]
Empirical Mean [0.18280205 0.80350724 0.01369071]
Probabilities: [0.23946792 0.74494729 0.01558479]
Second Order Uncertainty: [0.0020774096850272213, 0.00219863783640812, 0.00019286296810597546]
returning failed result because flag==0
color_method None
initializing a new example
List of samples to attack: [<AttackedText "although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . ">]
Final number of queries: 1
Datapoint: although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive']
Counter: {'sst2': {'negative': 4, 'positive': 16, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . $ the guesses were: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, low, high, high, high, low, high, high, high, high, low, high, high, high, high, low, high, high
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, high, low, high, high, high, high, low, high, high', 'predictions': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive', 'confidences': '\n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, high, low, high, high, high, high, low, high, high'}
Standarized predictions result: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive']
Standarized numerical confidence result: [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, high, low, high, high, high, high, low, high, high', 'predictions': ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive'], 'confidences': [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, high, low, high, high, high, high, low, high, high', 'predictions': ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive'], 'confidences': [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4], 'inference_step': 0, 'current_sample_id': 4}
Weighted count of prediction weight plus confidence weight: {'negative': 8.0, 'positive': 64.0, 'null': 0.0}
Sample ID: 4 and Inference step 0
Counts: {'sst2': {'negative': 8, 'positive': 32, 'null': 0}}
Numerical Confidences: [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4]
Weighted Counts: {'negative': 8.0, 'positive': 64.0, 'null': 0.0}
Alpha Vector: [9.0, 65.0, 1.0]
Empirical Mean [0.12037428 0.86707534 0.01255038]
Probabilities: [0.09578402 0.89457286 0.00964313]
Second Order Uncertainty: [0.0013894736842105264, 0.0015204678362573099, 0.00017309941520467836]
words_perturb [18, 8, 14, 17, 10]
start_i 8
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'JJ'), ('touches', 'NNS'), ('the', 'DT'), ('film', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('serious', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful affecting , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affects , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful afflicts , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful influencing , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful touched , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful touching , the film is a refreshingly serious look at young women . ">] 7
words_perturb [18, 8, 14, 17, 10]
start_i 10
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'NN'), ('impacted', 'VBD'), ('the', 'DT'), ('film', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('serious', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful impacted , the cinema is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the cinematic is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the cinematographic is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the cinematography is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the filmmaking is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the films is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the flick is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the kino is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movies is a refreshingly serious look at young women . ">] 10
words_perturb [18, 8, 14, 17, 10]
start_i 14
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'NN'), ('impacted', 'VBD'), ('the', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('serious', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly earnest look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly extreme look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly grave look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly gravest look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly grievous look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly heavy look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly major look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly severe look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at young women . ">] 9
words_perturb [18, 8, 14, 17, 10]
start_i 17
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'NN'), ('impacted', 'VBD'), ('the', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('weighty', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at jeune women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at juvenile women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youthful women . ">] 4
words_perturb [18, 8, 14, 17, 10]
start_i 18
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'NN'), ('impacted', 'VBD'), ('the', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('weighty', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('youngster', 'JJR'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster daughters . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster female . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster females . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster femme . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster femmes . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster girl . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster girls . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster mujer . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster wife . ">, <AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster woman . ">] 10
words_perturb [18, 8, 14, 17, 10]
start_i 8
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'JJ'), ('touches', 'NNS'), ('the', 'DT'), ('film', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('serious', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful affecting , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affects , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful afflicts , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful impacted , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful influencing , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful touched , the film is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful touching , the film is a refreshingly serious look at young women . ">] 7
words_perturb [18, 8, 14, 17, 10]
start_i 10
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'JJ'), ('affecting', 'VBG'), ('the', 'DT'), ('film', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('serious', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful affecting , the cinema is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematographic is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematography is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the filmmaking is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the films is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the flick is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the kino is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the movie is a refreshingly serious look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the movies is a refreshingly serious look at young women . ">] 10
words_perturb [18, 8, 14, 17, 10]
start_i 14
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'JJ'), ('affecting', 'VBG'), ('the', 'DT'), ('cinematic', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('serious', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly earnest look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly grave look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly gravest look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly grievous look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly heavy look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly major look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly severe look at young women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly weighty look at young women . ">] 9
words_perturb [18, 8, 14, 17, 10]
start_i 17
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'JJ'), ('affecting', 'VBG'), ('the', 'DT'), ('cinematic', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('extreme', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('young', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at jeune women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at juvenile women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youngster women . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful women . ">] 4
words_perturb [18, 8, 14, 17, 10]
start_i 18
pos_tags nltk [('although', 'IN'), ('laced', 'VBN'), ('with', 'IN'), ('humor', 'NN'), ('and', 'CC'), ('a', 'DT'), ('few', 'JJ'), ('fanciful', 'JJ'), ('affecting', 'VBG'), ('the', 'DT'), ('cinematic', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('refreshingly', 'RB'), ('extreme', 'JJ'), ('look', 'NN'), ('at', 'IN'), ('youthful', 'JJ'), ('women', 'NNS')]
replaced_with_synonyms should be 10? [<AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful daughters . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful female . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful females . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful femme . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful femmes . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful girl . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful girls . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful mujer . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful wife . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful woman . ">] 10
List of samples to attack: [<AttackedText "although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster femme . ">, <AttackedText "although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful girl . ">]
Final number of queries: 5
Datapoint: although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster femme . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster femme .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive']
Counter: {'sst2': {'negative': 6, 'positive': 14, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$although laced with humor and a few fanciful impacted , the movie is a refreshingly weighty look at youngster femme . $ the guesses were: ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high
Raw output: {'raw_responses': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high', 'predictions': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive', 'confidences': '\n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high'}
Standarized predictions result: ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive']
Standarized numerical confidence result: [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4]
Guessed output and label list: Guess: ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high', 'predictions': ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], 'confidences': [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high', 'predictions': ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], 'confidences': [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4], 'inference_step': 0, 'current_sample_id': 4}
Weighted count of prediction weight plus confidence weight: {'negative': 15.0, 'positive': 56.0, 'null': 0.0}
Sample ID: 4 and Inference step 0
Counts: {'sst2': {'negative': 12, 'positive': 28, 'null': 0}}
Numerical Confidences: [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4]
Weighted Counts: {'negative': 15.0, 'positive': 56.0, 'null': 0.0}
Alpha Vector: [16.0, 57.0, 1.0]
Empirical Mean [0.21738541 0.76942636 0.01318822]
Probabilities: [0.14130845 0.85080799 0.00788356]
Second Order Uncertainty: [0.0022595568541514486, 0.0023593864134404674, 0.00017774531288044802]
Datapoint: although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful girl . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful girl .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive']
Counter: {'sst2': {'negative': 6, 'positive': 14, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$although laced with humor and a few fanciful affecting , the cinematic is a refreshingly extreme look at youthful girl . $ the guesses were: ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high
Raw output: {'raw_responses': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high', 'predictions': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive', 'confidences': '\n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high'}
Standarized predictions result: ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive']
Standarized numerical confidence result: [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4]
Guessed output and label list: Guess: ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high', 'predictions': ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], 'confidences': [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive, Negative, Positive, Positive \n\nConfidences: high, high, medium, high, high, low, high, high, medium, high, high, low, high, high, medium, high, high, low, high, high', 'predictions': ['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive'], 'confidences': [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4], 'inference_step': 1, 'current_sample_id': 4}
Weighted count of prediction weight plus confidence weight: {'negative': 15.0, 'positive': 56.0, 'null': 0.0}
Sample ID: 4 and Inference step 1
Counts: {'sst2': {'negative': 12, 'positive': 28, 'null': 0}}
Numerical Confidences: [4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4]
Weighted Counts: {'negative': 15.0, 'positive': 56.0, 'null': 0.0}
Alpha Vector: [16.0, 57.0, 1.0]
Empirical Mean [0.2178988  0.76899904 0.01310216]
Probabilities: [0.20268672 0.78879148 0.0085218 ]
Second Order Uncertainty: [0.0022595568541514486, 0.0023593864134404674, 0.00017774531288044802]
returning failed result because flag==0
color_method None
initializing a new example
List of samples to attack: [<AttackedText "you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . ">]
Final number of queries: 1
Datapoint: you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive']
Counter: {'sst2': {'negative': 0, 'positive': 20, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive', 'confidences': '\n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']
Standarized numerical confidence result: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], 'inference_step': 0, 'current_sample_id': 5}
Weighted count of prediction weight plus confidence weight: {'negative': 0.0, 'positive': 100.0, 'null': 0.0}
Sample ID: 5 and Inference step 0
Counts: {'sst2': {'negative': 0, 'positive': 40, 'null': 0}}
Numerical Confidences: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Weighted Counts: {'negative': 0.0, 'positive': 100.0, 'null': 0.0}
Alpha Vector: [1.0, 101.0, 1.0]
Empirical Mean [0.00973557 0.98100686 0.00925757]
Probabilities: [7.50104025e-04 9.90474758e-01 8.77513777e-03]
Second Order Uncertainty: [9.24469064727336e-05, 0.00018308112850482536, 9.24469064727336e-05]
words_perturb [7, 3, 5, 14, 2]
start_i 2
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('have', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'RB'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [7, 3, 5, 14, 2]
start_i 3
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('have', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'RB'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ai to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't did to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't enjoys to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't fi to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't got to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't had to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't has to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't possess to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ter to know about music to appreciate the film 's easygoing blend of comedy and romance . ">] 10
words_perturb [7, 3, 5, 14, 2]
start_i 5
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('ha', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'RB'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ha to fathom about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to hear about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knowing about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knows about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to realise about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to sais about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to savoir about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to soaps about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to understand about music to appreciate the film 's easygoing blend of comedy and romance . ">] 10
words_perturb [7, 3, 5, 14, 2]
start_i 7
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('ha', 'VB'), ('to', 'TO'), ('knew', 'VB'), ('about', 'IN'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ha to knew about concert to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about concerto to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about concerts to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about gig to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about lok to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about musicians to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to knew about orchestra to appreciate the film 's easygoing blend of comedy and romance . ">] 8
words_perturb [7, 3, 5, 14, 2]
start_i 14
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('ha', 'VB'), ('to', 'TO'), ('knew', 'VB'), ('about', 'IN'), ('musica', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing amalgam of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing blended of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing blending of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing blends of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing mingling of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing mix of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing mixes of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing mixing of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing mixture of comedy and romance . ">, <AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing mixtures of comedy and romance . ">] 10
words_perturb [7, 3, 5, 14, 2]
start_i 2
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('have', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'RB'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [7, 3, 5, 14, 2]
start_i 3
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('have', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'RB'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ai to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't did to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't enjoys to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't fi to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't got to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ha to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't had to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't has to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't possess to know about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ter to know about music to appreciate the film 's easygoing blend of comedy and romance . ">] 10
words_perturb [7, 3, 5, 14, 2]
start_i 5
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('ai', 'VB'), ('to', 'TO'), ('know', 'VB'), ('about', 'RB'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ai to fathom about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to hear about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to knew about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to knowing about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to knows about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to realise about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to sais about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to soaps about music to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to understand about music to appreciate the film 's easygoing blend of comedy and romance . ">] 10
words_perturb [7, 3, 5, 14, 2]
start_i 7
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('ai', 'VB'), ('to', 'TO'), ('savoir', 'VB'), ('about', 'IN'), ('music', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ai to savoir about concert to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about concerto to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about concerts to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about gig to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about lok to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musicians to appreciate the film 's easygoing blend of comedy and romance . ">, <AttackedText "you do n't ai to savoir about orchestra to appreciate the film 's easygoing blend of comedy and romance . ">] 8
words_perturb [7, 3, 5, 14, 2]
start_i 14
pos_tags nltk [('you', 'PRP'), ('do', 'VBP'), ("n't", 'RB'), ('ai', 'VB'), ('to', 'TO'), ('savoir', 'VB'), ('about', 'IN'), ('musica', 'NN'), ('to', 'TO'), ('appreciate', 'VB'), ('the', 'DT'), ('film', 'NN'), ('s', 'NN'), ('easygoing', 'VBG'), ('blend', 'NN'), ('of', 'IN'), ('comedy', 'NN'), ('and', 'CC'), ('romance', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing amalgam of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing blended of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing blending of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing blends of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mingling of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mix of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mixes of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mixing of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mixture of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mixtures of comedy and romance . ">] 10
List of samples to attack: [<AttackedText "you do n't ha to knew about musica to appreciate the film 's easygoing blending of comedy and romance . ">, <AttackedText "you do n't ai to savoir about musica to appreciate the film 's easygoing mingling of comedy and romance . ">]
Final number of queries: 5
Datapoint: you do n't ha to knew about musica to appreciate the film 's easygoing blending of comedy and romance . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$you do n't ha to knew about musica to appreciate the film 's easygoing blending of comedy and romance .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 1, 'positive': 19, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$you do n't ha to knew about musica to appreciate the film 's easygoing blending of comedy and romance . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], 'inference_step': 0, 'current_sample_id': 5}
Weighted count of prediction weight plus confidence weight: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Sample ID: 5 and Inference step 0
Counts: {'sst2': {'negative': 2, 'positive': 38, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Weighted Counts: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Alpha Vector: [6.0, 77.0, 1.0]
Empirical Mean [0.07087383 0.91717622 0.01194995]
Probabilities: [0.08514369 0.896457   0.01839931]
Second Order Uncertainty: [0.00078031212484994, 0.0008986928104575163, 0.00013838868880885688]
Datapoint: you do n't ai to savoir about musica to appreciate the film 's easygoing mingling of comedy and romance . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$you do n't ai to savoir about musica to appreciate the film 's easygoing mingling of comedy and romance .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 5, 'positive': 15, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$you do n't ai to savoir about musica to appreciate the film 's easygoing mingling of comedy and romance . $ the guesses were: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low', 'predictions': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low'}
Standarized predictions result: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low', 'predictions': ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low, high, high, high, low', 'predictions': ['positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2], 'inference_step': 1, 'current_sample_id': 5}
Weighted count of prediction weight plus confidence weight: {'negative': 10.0, 'positive': 60.0, 'null': 0.0}
Sample ID: 5 and Inference step 1
Counts: {'sst2': {'negative': 10, 'positive': 30, 'null': 0}}
Numerical Confidences: [4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2]
Weighted Counts: {'negative': 10.0, 'positive': 60.0, 'null': 0.0}
Alpha Vector: [11.0, 61.0, 1.0]
Empirical Mean [0.15107724 0.83500872 0.01391405]
Probabilities: [0.12568589 0.85216405 0.02215006]
Second Order Uncertainty: [0.0017294457151841277, 0.0018562379230422014, 0.00018258077931562638]
returning failed result because flag==0
color_method None
initializing a new example
List of samples to attack: [<AttackedText "the mesmerizing performances of the leads keep the film grounded and keep the audience riveted . ">]
Final number of queries: 1
Datapoint: the mesmerizing performances of the leads keep the film grounded and keep the audience riveted . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$the mesmerizing performances of the leads keep the film grounded and keep the audience riveted .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive']
Counter: {'sst2': {'negative': 0, 'positive': 20, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$the mesmerizing performances of the leads keep the film grounded and keep the audience riveted . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive', 'confidences': '\n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']
Standarized numerical confidence result: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], 'inference_step': 0, 'current_sample_id': 6}
Weighted count of prediction weight plus confidence weight: {'negative': 0.0, 'positive': 100.0, 'null': 0.0}
Sample ID: 6 and Inference step 0
Counts: {'sst2': {'negative': 0, 'positive': 40, 'null': 0}}
Numerical Confidences: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Weighted Counts: {'negative': 0.0, 'positive': 100.0, 'null': 0.0}
Alpha Vector: [1.0, 101.0, 1.0]
Empirical Mean [0.00959493 0.98034863 0.01005644]
Probabilities: [0.00234519 0.96835268 0.02930214]
Second Order Uncertainty: [9.24469064727336e-05, 0.00018308112850482536, 9.24469064727336e-05]
words_perturb [8, 6, 14, 2, 1]
start_i 1
pos_tags nltk [('the', 'DT'), ('mesmerizing', 'NN'), ('performances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('keep', 'VB'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the beguiling performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the enthralling performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the entrancing performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the mesmerising performances of the leads keep the film grounded and keep the audience riveted . ">] 6
words_perturb [8, 6, 14, 2, 1]
start_i 2
pos_tags nltk [('the', 'DT'), ('bewitching', 'NN'), ('performances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('keep', 'VB'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the bewitching concertos of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching concerts of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching depictions of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching executions of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpreting of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching representations of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching reproductions of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching spectacle of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching spectacles of the leads keep the film grounded and keep the audience riveted . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 6
pos_tags nltk [('the', 'DT'), ('bewitching', 'NN'), ('interpretations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('keep', 'VB'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the bewitching interpretations of the leads conserve the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads conserving the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads keeping the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads maintain the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads maintaining the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads preserve the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads preserving the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retaining the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads sustain the film grounded and keep the audience riveted . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 8
pos_tags nltk [('the', 'DT'), ('bewitching', 'NN'), ('interpretations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('retain', 'VBP'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the bewitching interpretations of the leads retain the cinema grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the cinematic grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the cinematographic grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the cinematography grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the filmmaking grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the films grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the flick grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the movie grounded and keep the audience riveted . ">, <AttackedText "the bewitching interpretations of the leads retain the movies grounded and keep the audience riveted . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 14
pos_tags nltk [('the', 'DT'), ('bewitching', 'NN'), ('interpretations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('retain', 'VBP'), ('the', 'DT'), ('kino', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience captivated . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience enraptured . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience enthralled . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience entranced . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience fascinated . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience intrigued . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience mesmerised . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience preoccupied . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience spellbound . ">, <AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience transfixed . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 1
pos_tags nltk [('the', 'DT'), ('mesmerizing', 'NN'), ('performances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('keep', 'VB'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the beguiling performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the bewitching performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the enthralling performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the entrancing performances of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the mesmerising performances of the leads keep the film grounded and keep the audience riveted . ">] 6
words_perturb [8, 6, 14, 2, 1]
start_i 2
pos_tags nltk [('the', 'DT'), ('captivating', 'NN'), ('performances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('keep', 'VB'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the captivating concertos of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating concerts of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating depictions of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating executions of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating interpretations of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating interpreting of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating reproductions of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating spectacle of the leads keep the film grounded and keep the audience riveted . ">, <AttackedText "the captivating spectacles of the leads keep the film grounded and keep the audience riveted . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 6
pos_tags nltk [('the', 'DT'), ('captivating', 'VBG'), ('representations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('keep', 'VB'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the captivating representations of the leads conserve the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads conserving the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads keeping the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads maintain the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads maintaining the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserving the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads retain the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads retaining the film grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads sustain the film grounded and keep the audience riveted . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 8
pos_tags nltk [('the', 'DT'), ('captivating', 'VBG'), ('representations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('preserve', 'VBP'), ('the', 'DT'), ('film', 'NN'), ('grounded', 'VBD'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the captivating representations of the leads preserve the cinema grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the cinematic grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the cinematographic grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the cinematography grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the filmmaking grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the films grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the flick grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the kino grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience riveted . ">, <AttackedText "the captivating representations of the leads preserve the movies grounded and keep the audience riveted . ">] 10
words_perturb [8, 6, 14, 2, 1]
start_i 14
pos_tags nltk [('the', 'DT'), ('captivating', 'VBG'), ('representations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('leads', 'NNS'), ('preserve', 'VBP'), ('the', 'DT'), ('movie', 'NN'), ('grounded', 'VBN'), ('and', 'CC'), ('keep', 'VB'), ('the', 'DT'), ('audience', 'NN'), ('riveted', 'VBD')]
replaced_with_synonyms should be 10? [<AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience captivated . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience enraptured . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience enthralled . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience entranced . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience fascinated . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience intrigued . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience mesmerised . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience preoccupied . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience spellbound . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience transfixed . ">] 10
List of samples to attack: [<AttackedText "the bewitching interpretations of the leads retain the kino grounded and keep the audience mesmerised . ">, <AttackedText "the captivating representations of the leads preserve the movie grounded and keep the audience entranced . ">]
Final number of queries: 5
Datapoint: the bewitching interpretations of the leads retain the kino grounded and keep the audience mesmerised . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$the bewitching interpretations of the leads retain the kino grounded and keep the audience mesmerised .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative']
Counter: {'sst2': {'negative': 1, 'positive': 19, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$the bewitching interpretations of the leads retain the kino grounded and keep the audience mesmerised . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative', 'confidences': '\n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative']
Standarized numerical confidence result: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Negative \n\nConfidences: high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, high, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative'], 'confidences': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5], 'inference_step': 0, 'current_sample_id': 6}
Weighted count of prediction weight plus confidence weight: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Sample ID: 6 and Inference step 0
Counts: {'sst2': {'negative': 2, 'positive': 38, 'null': 0}}
Numerical Confidences: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5]
Weighted Counts: {'negative': 5.0, 'positive': 76.0, 'null': 0.0}
Alpha Vector: [6.0, 77.0, 1.0]
Empirical Mean [0.07152081 0.91607151 0.01240768]
Probabilities: [0.06112431 0.92366879 0.0152069 ]
Second Order Uncertainty: [0.00078031212484994, 0.0008986928104575163, 0.00013838868880885688]
Datapoint: the captivating representations of the leads preserve the movie grounded and keep the audience entranced . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$the captivating representations of the leads preserve the movie grounded and keep the audience entranced .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive']
Counter: {'sst2': {'negative': 0, 'positive': 20, 'null': 0}}
Max class based on prediction: positive
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$the captivating representations of the leads preserve the movie grounded and keep the audience entranced . $ the guesses were: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest
Raw output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive', 'confidences': '\n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest'}
Standarized predictions result: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']
Standarized numerical confidence result: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Guessed output and label list: Guess: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]}
Output that needs aggregation: {'raw_responses': '\n\nPositive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive, Positive \n\nConfidences: highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest, highest', 'predictions': ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive'], 'confidences': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], 'inference_step': 1, 'current_sample_id': 6}
Weighted count of prediction weight plus confidence weight: {'negative': 0.0, 'positive': 100.0, 'null': 0.0}
Sample ID: 6 and Inference step 1
Counts: {'sst2': {'negative': 0, 'positive': 40, 'null': 0}}
Numerical Confidences: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Weighted Counts: {'negative': 0.0, 'positive': 100.0, 'null': 0.0}
Alpha Vector: [1.0, 101.0, 1.0]
Empirical Mean [0.00983037 0.98033027 0.00983936]
Probabilities: [0.010029   0.98262349 0.00734751]
Second Order Uncertainty: [9.24469064727336e-05, 0.00018308112850482536, 9.24469064727336e-05]
returning failed result because flag==0
color_method None
initializing a new example
List of samples to attack: [<AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">]
Final number of queries: 1
Datapoint: we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 10, 'positive': 10, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . $ the guesses were: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high
Raw output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive', 'confidences': '\n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high'}
Standarized predictions result: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Guessed output and label list: Guess: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 20, 'positive': 20, 'null': 0}}
Numerical Confidences: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Weighted Counts: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Alpha Vector: [34.0, 37.0, 1.0]
Empirical Mean [0.47382568 0.51228719 0.01388714]
Probabilities: [0.47892429 0.48693167 0.03414403]
Second Order Uncertainty: [0.0034140876035853203, 0.0034220150515812614, 0.0001876162692372738]
words_perturb [6, 1, 17, 10, 5]
start_i 1
pos_tags nltk [('we', 'PRP'), ('root', 'VBP'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('paul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we backgrounds for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we origin for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we origins for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we provenance for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we racine for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we rooted for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we roots for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we sources for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we underlying for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">] 10
words_perturb [6, 1, 17, 10, 5]
start_i 5
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('paul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we source for ( clara and pablo ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paolo ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pauli ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paulie ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paulo ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paulus ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and poole ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and poul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to pity . ">] 9
words_perturb [6, 1, 17, 10, 5]
start_i 6
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('pul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [6, 1, 17, 10, 5]
start_i 10
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('pul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we source for ( clara and pul ) , even like them , though maybe it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though possibly it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though potentially it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though presumably it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity . ">] 5
words_perturb [6, 1, 17, 10, 5]
start_i 17
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('pul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('probably', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to compassion . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to disgrace . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to dishonor . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to empathy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to ignominy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to shame . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to shaming . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to sympathy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to worth . ">] 10
words_perturb [6, 1, 17, 10, 5]
start_i 1
pos_tags nltk [('we', 'PRP'), ('root', 'VBP'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('paul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we backgrounds for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we origin for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we origins for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we provenance for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we racine for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we rooted for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we roots for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we sources for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we underlying for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">] 10
words_perturb [6, 1, 17, 10, 5]
start_i 5
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('paul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we source for ( clara and pablo ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paolo ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pauli ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paulie ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paulo ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and paulus ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and poole ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and poul ) , even like them , though perhaps it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to pity . ">] 9
words_perturb [6, 1, 17, 10, 5]
start_i 6
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('pul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [] 0
words_perturb [6, 1, 17, 10, 5]
start_i 10
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('pul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('perhaps', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we source for ( clara and pul ) , even like them , though maybe it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though possibly it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though potentially it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though presumably it 's an emotion closer to pity . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity . ">] 5
words_perturb [6, 1, 17, 10, 5]
start_i 17
pos_tags nltk [('we', 'PRP'), ('source', 'NN'), ('for', 'IN'), ('clara', 'NN'), ('and', 'CC'), ('pul', 'VB'), ('even', 'RB'), ('like', 'IN'), ('them', 'PRP'), ('though', 'IN'), ('probably', 'RB'), ('it', 'PRP'), ('s', 'VBD'), ('an', 'DT'), ('emotion', 'NN'), ('closer', 'NN'), ('to', 'TO'), ('pity', 'NN')]
replaced_with_synonyms should be 10? [<AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to compassion . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to disgrace . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to dishonor . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to empathy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to ignominy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to shame . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to shaming . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to sympathy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to worth . ">] 10
List of samples to attack: [<AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to sympathy . ">, <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">]
Final number of queries: 5
Datapoint: we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to sympathy . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to sympathy .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 10, 'positive': 10, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to sympathy . $ the guesses were: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high
Raw output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive', 'confidences': '\n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high'}
Standarized predictions result: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Guessed output and label list: Guess: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 20, 'positive': 20, 'null': 0}}
Numerical Confidences: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Weighted Counts: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Alpha Vector: [34.0, 37.0, 1.0]
Empirical Mean [0.47311145 0.51372668 0.01316188]
Probabilities: [0.41211195 0.56962895 0.0182591 ]
Second Order Uncertainty: [0.0034140876035853203, 0.0034220150515812614, 0.0001876162692372738]
Datapoint: we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative']
Counter: {'sst2': {'negative': 14, 'positive': 6, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . $ the guesses were: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low, low
Raw output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative \n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low, low', 'predictions': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative', 'confidences': '\n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low, low'}
Standarized predictions result: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative']
Standarized numerical confidence result: [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2]
Guessed output and label list: Guess: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative \n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low, low', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], 'confidences': [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative \n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low, low', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], 'confidences': [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2], 'inference_step': 1, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 34.0, 'positive': 23.0, 'null': 0.0}
Sample ID: 7 and Inference step 1
Counts: {'sst2': {'negative': 28, 'positive': 12, 'null': 0}}
Numerical Confidences: [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2]
Weighted Counts: {'negative': 34.0, 'positive': 23.0, 'null': 0.0}
Alpha Vector: [35.0, 24.0, 1.0]
Empirical Mean [0.58214421 0.40157004 0.01628574]
Probabilities: [0.50842022 0.48160573 0.00997404]
Second Order Uncertainty: [0.003984517304189436, 0.003934426229508197, 0.0002686703096539162]
TextHoaxer Original Text: 
 <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we root for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
semantic_sims1 tensor([0.7906])
List of samples to attack: [<AttackedText "we root for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">]
Final number of queries: 6
Datapoint: we root for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we root for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 10, 'positive': 10, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we root for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . $ the guesses were: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high
Raw output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive', 'confidences': '\n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high'}
Standarized predictions result: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Guessed output and label list: Guess: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 20, 'positive': 20, 'null': 0}}
Numerical Confidences: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Weighted Counts: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Alpha Vector: [34.0, 37.0, 1.0]
Empirical Mean [0.47310918 0.51312839 0.01376243]
Probabilities: [0.43554773 0.5612089  0.00324337]
Second Order Uncertainty: [0.0034140876035853203, 0.0034220150515812614, 0.0001876162692372738]
qrs3 3
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to penalty . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
semantic_sims1 tensor([0.7742])
List of samples to attack: [<AttackedText "we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to penalty . ">]
Final number of queries: 5
Datapoint: we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to penalty . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to penalty .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative']
Counter: {'sst2': {'negative': 14, 'positive': 6, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to penalty . $ the guesses were: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low
Raw output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative \n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low', 'predictions': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative', 'confidences': '\n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low'}
Standarized predictions result: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative']
Standarized numerical confidence result: [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 1]
Guessed output and label list: Guess: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative \n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], 'confidences': [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 1]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative \n\nConfidences: high, high, medium, high, low, high, low, low, high, low, low, high, low, low, high, low, low, high, low', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative'], 'confidences': [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 1], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 33.0, 'positive': 23.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 28, 'positive': 12, 'null': 0}}
Numerical Confidences: [4, 4, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 1]
Weighted Counts: {'negative': 33.0, 'positive': 23.0, 'null': 0.0}
Alpha Vector: [34.0, 24.0, 1.0]
Empirical Mean [0.5775325  0.40501341 0.01745409]
Probabilities: [0.45108159 0.53400432 0.01491408]
Second Order Uncertainty: [0.004069711768648856, 0.004021832806664752, 0.0002776979795078043]
qrs3 4
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to penalty . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
semantic_sims1 tensor([0.7275])
List of samples to attack: [<AttackedText "we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to penalty . ">]
Final number of queries: 6
Datapoint: we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to penalty . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to penalty .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 10, 'positive': 10, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and pul ) , even like them , though perhaps it 's an emotion closer to penalty . $ the guesses were: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest
Raw output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest', 'predictions': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive', 'confidences': '\n\nConfidences: low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest'}
Standarized predictions result: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]
Guessed output and label list: Guess: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest, low, medium, high, highest', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 30.0, 'positive': 40.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 20, 'positive': 20, 'null': 0}}
Numerical Confidences: [2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]
Weighted Counts: {'negative': 30.0, 'positive': 40.0, 'null': 0.0}
Alpha Vector: [31.0, 41.0, 1.0]
Empirical Mean [0.42647233 0.56005947 0.0134682 ]
Probabilities: [0.5716711  0.42417397 0.00415493]
Second Order Uncertainty: [0.0033016690926242435, 0.0033270275341958583, 0.00018258077931562638]
qrs3 5
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
semantic_sims1 tensor([0.7703])
List of samples to attack: [<AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity . ">]
Final number of queries: 7
Datapoint: we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 13, 'positive': 7, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to pity . $ the guesses were: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, low, high, low, high, low, high
Raw output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive \n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, low, high, low, high, low, high', 'predictions': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive', 'confidences': '\n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, low, high, low, high, low, high'}
Standarized predictions result: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1]
Guessed output and label list: Guess: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive \n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, low, high, low, high, low, high', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive \n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, low, high, low, high, low, high', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 42.0, 'positive': 20.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 26, 'positive': 14, 'null': 0}}
Numerical Confidences: [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1]
Weighted Counts: {'negative': 42.0, 'positive': 20.0, 'null': 0.0}
Alpha Vector: [43.0, 21.0, 1.0]
Empirical Mean [0.65999253 0.32499985 0.01500762]
Probabilities: [0.61167824 0.37437584 0.01394592]
Second Order Uncertainty: [0.0033925049309664695, 0.0033136094674556214, 0.00022951407566792182]
qrs3 6
choices [(5, tensor(0.7742)), (17, tensor(0.7703))]
List of samples to attack: [<AttackedText "we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to penalty . ">]
Final number of queries: 8
List of samples to attack: [<AttackedText "we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . ">]
Final number of queries: 9
Datapoint: we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive']
Counter: {'sst2': {'negative': 15, 'positive': 5, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . $ the guesses were: ['negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, high
Raw output: {'raw_responses': '\n\nNegative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive \n\nConfidences: high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, high', 'predictions': '\n\nNegative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive', 'confidences': '\n\nConfidences: high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, high'}
Standarized predictions result: ['negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4]
Guessed output and label list: Guess: ['negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive \n\nConfidences: high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, high', 'predictions': ['negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive'], 'confidences': [4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive, Negative, Negative, Negative, Positive \n\nConfidences: high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, medium, high, high, high, high', 'predictions': ['negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive'], 'confidences': [4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 60.0, 'positive': 16.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 30, 'positive': 10, 'null': 0}}
Numerical Confidences: [4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4]
Weighted Counts: {'negative': 60.0, 'positive': 16.0, 'null': 0.0}
Alpha Vector: [61.0, 17.0, 1.0]
Empirical Mean [0.77029753 0.21685562 0.01284685]
Probabilities: [0.71817602 0.24152019 0.04030379]
Second Order Uncertainty: [0.002199166800192277, 0.0021110398974523315, 0.00015622496394808525]
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we root for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
semantic_sims1 tensor([0.9358])
List of samples to attack: [<AttackedText "we root for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . ">]
Final number of queries: 10
Datapoint: we root for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we root for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive']
Counter: {'sst2': {'negative': 10, 'positive': 10, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we root for ( clara and paul ) , even like them , though probably it 's an emotion closer to pity . $ the guesses were: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high
Raw output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive', 'confidences': '\n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high'}
Standarized predictions result: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Guessed output and label list: Guess: ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive, Negative, Positive \n\nConfidences: high, high, low, high, high, medium, high, high, low, high, medium, high, low, high, high, medium, high, low, high, high', 'predictions': ['negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive'], 'confidences': [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 20, 'positive': 20, 'null': 0}}
Numerical Confidences: [4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3, 4, 2, 4, 4, 3, 4, 2, 4, 4]
Weighted Counts: {'negative': 33.0, 'positive': 36.0, 'null': 0.0}
Alpha Vector: [34.0, 37.0, 1.0]
Empirical Mean [0.47279765 0.51437773 0.01282462]
Probabilities: [0.45701062 0.52866462 0.01432477]
Second Order Uncertainty: [0.0034140876035853203, 0.0034220150515812614, 0.0001876162692372738]
qrs3 9
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
semantic_sims1 tensor([0.8570])
List of samples to attack: [<AttackedText "we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">]
Final number of queries: 11
Datapoint: we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . 
predict_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>Provide your 20 best guess for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guesses, either positive or negative; not a complete sentence, just the guesses! Separated by a comma, for example [Negative, Positive, Positive, Negative ... x20]>

The text is:$we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity .  Guesses:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw prediction: ['\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive']
Counter: {'sst2': {'negative': 13, 'positive': 7, 'null': 0}}
Max class based on prediction: negative
confidence_prompt: <|begin_of_text|><|start_header_id|>user<|end_header_id|>You're a model that needs to give the confidence of answers being correct. The previeous prompt was $Provide your 20 best guesses for the following text (positive, negative). Give ONLY the guesses, no other words or explanation.

For example:

Guesses: <most likely guess, either positive or negative; not a complete sentence, just the guesses!>

The text is:$we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . $ the guesses were: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive'], given these guesses provide the verbal confidences that your guesses are correct. Give ONLY the verbal confidences, no other words or explanation.

For example:
\Confidences: <the confidences, from either lowest, low, medium, high, highest that your guesses are correct, without any extra commentary whatsoever, for example [lowest, low, medium, high, highest ...]; just the confidence! Separated by a coma> Confidences:<|eot_id|><|start_header_id|>assistant<|end_header_id|>
passing
Generated raw confidence:  

Confidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, medium, high, low, high, low, high
Raw output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive \n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, medium, high, low, high, low, high', 'predictions': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive', 'confidences': '\n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, medium, high, low, high, low, high'}
Standarized predictions result: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive']
Standarized numerical confidence result: [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 3, 4, 2, 4, 2, 4, 1]
Guessed output and label list: Guess: ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive'], Label List: ['negative', 'positive']
Standarized output: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive \n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, medium, high, low, high, low, high', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive'], 'confidences': [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 3, 4, 2, 4, 2, 4, 1]}
Output that needs aggregation: {'raw_responses': '\n\nNegative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive, Negative, Positive, Negative, Negative, Positive, Negative, Negative, Positive \n\nConfidences: high, high, medium, high, low, high, high, low, high, low, high, low, high, medium, high, low, high, low, high', 'predictions': ['negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive'], 'confidences': [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 3, 4, 2, 4, 2, 4, 1], 'inference_step': 0, 'current_sample_id': 7}
Weighted count of prediction weight plus confidence weight: {'negative': 42.0, 'positive': 21.0, 'null': 0.0}
Sample ID: 7 and Inference step 0
Counts: {'sst2': {'negative': 26, 'positive': 14, 'null': 0}}
Numerical Confidences: [4, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 3, 4, 2, 4, 2, 4, 1]
Weighted Counts: {'negative': 42.0, 'positive': 21.0, 'null': 0.0}
Alpha Vector: [43.0, 22.0, 1.0]
Empirical Mean [0.64947536 0.33623108 0.01429356]
Probabilities: [0.60110284 0.38964148 0.00925568]
Second Order Uncertainty: [0.0033887038636021, 0.003316749585406302, 0.0002227156229869934]
qrs3 10
choices [(10, tensor(0.8570))]
List of samples to attack: [<AttackedText "we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">]
Final number of queries: 12
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_text_joint <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
TextHoaxer Perturbed Text: 
 <AttackedText "we source for ( clara and pul ) , even like them , though probably it 's an emotion closer to penalty . ">
choices []
after choices random_text ['we', 'source', 'for', 'clara', 'and', 'paul', 'even', 'like', 'them', 'though', 'perhaps', 'it', 's', 'an', 'emotion', 'closer', 'to', 'pity']
1 12
attacked_text <AttackedText "we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
new_random_text_joint <AttackedText "we source for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . ">
